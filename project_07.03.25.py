import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor

# ==========================
# 1. –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
# ==========================
st.title("üìà –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Ä–æ–≤–Ω—è —Å–∞–º–æ—É–±–∏–π—Å—Ç–≤")
st.write(
    """
    –î–∞–Ω–Ω—ã–π –¥–µ–º–æ-–ø—Ä–æ–µ–∫—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö, 
    –æ–±—É—á–µ–Ω–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∑–∞–¥–∞—á–∏ 
    "–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Ä–æ–≤–Ω—è —Å–∞–º–æ—É–±–∏–π—Å—Ç–≤ (–Ω–∞ 100k) –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –∏ —Å–æ—Ü–∏–∞–ª—å–Ω–æ-—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π".
    """
)

# ==========================
# 2. –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
# ==========================
st.sidebar.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")

test_size = st.sidebar.slider("–î–æ–ª—è —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ (test_size)", 0.1, 0.5, 0.2, 0.05)
max_depth = st.sidebar.slider("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞ (Decision Tree)", 1, 20, 5, 1)
n_estimators = st.sidebar.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤ (Random Forest)", 10, 300, 100, 10)
k_neighbors = st.sidebar.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Å–µ–¥–µ–π (KNN)", 1, 15, 5, 1)

# ==========================
# 3. –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
# ==========================
@st.cache_data
def load_and_preprocess_data(csv_file: str):
    # –ß–∏—Ç–∞–µ–º CSV
    data = pd.read_csv(csv_file)
    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ —Å—Ç–æ–ª–±—Ü—ã, —á–∏—Å—Ç–∏–º NaN –∏ —Ç.–¥. ‚Äì —Å–æ–≥–ª–∞—Å–Ω–æ –≤–∞—à–µ–º—É –ø–∞–π–ø–ª–∞–π–Ω—É
    # –ù–∞–ø—Ä–∏–º–µ—Ä:
    data.drop(columns=['country-year', 'HDI for year'], inplace=True, errors='ignore')

    # –ü–µ—Ä–µ–∏–º–µ–Ω—É–µ–º –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –∫–æ–ª–æ–Ω–∫–∏, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    data.rename(columns={
        'suicides/100k pop': 'suicides_100k_pop',
        'gdp_for_year ($)': 'gdp_for_year',
        'gdp_per_capita ($)': 'gdp_per_capita'
    }, inplace=True, errors='ignore')

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º 'gdp_for_year' (–µ—Å–ª–∏ –µ—Å—Ç—å –∑–∞–ø—è—Ç—ã–µ)
    if 'gdp_for_year' in data.columns and data['gdp_for_year'].dtype == 'object':
        data['gdp_for_year'] = data['gdp_for_year'].str.replace(",", "", regex=False).astype(float, errors='ignore')

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã (sex, age, generation) –≤ —á–∏—Å–ª–∞
    age_map = {
        '5-14 years': 0, '15-24 years': 1, '25-34 years': 2,
        '35-54 years': 3, '55-74 years': 4, '75+ years': 5
    }
    if 'age' in data.columns:
        data['age'] = data['age'].map(age_map).fillna(-1)

    sex_map = {'male': 0, 'female': 1}
    if 'sex' in data.columns:
        data['sex'] = data['sex'].map(sex_map).fillna(-1)

    if 'generation' in data.columns:
        data = pd.get_dummies(data, columns=['generation'])

    # –£–¥–∞–ª–∏–º –¥—É–±–ª–∏–∫–∞—Ç—ã, –µ—Å–ª–∏ –µ—Å—Ç—å
    data.drop_duplicates(inplace=True)

    # –£–¥–∞–ª–∏–º –ø—Ä–æ–ø—É—Å–∫–∏ –≤ —Ü–µ–ª–µ–≤–æ–º —Å—Ç–æ–ª–±—Ü–µ, –µ—Å–ª–∏ —Ç–∞–∫–æ–≤—ã–µ –≤–¥—Ä—É–≥ –µ—Å—Ç—å
    data.dropna(subset=['suicides_100k_pop'], inplace=True)

    # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–ø–æ –∂–µ–ª–∞–Ω–∏—é).
    # –í—ã–±–µ—Ä–µ–º –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è —Å–∫–µ–π–ª–∏–Ω–≥–∞:
    # (–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ–Ω–∏ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö)
    numeric_cols = ['population', 'gdp_for_year', 'gdp_per_capita']
    for col in numeric_cols:
        if col not in data.columns:
            numeric_cols.remove(col)

    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    data[numeric_cols] = scaler.fit_transform(data[numeric_cols])

    return data

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ master.csv –ª–µ–∂–∏—Ç –≤ –ø–∞–ø–∫–µ —Å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º).
# –ü—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ st.file_uploader(...)
csv_file = "master.csv"
data = load_and_preprocess_data(csv_file)

# ==========================
# 4. –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
# ==========================
st.subheader("–û–±–∑–æ—Ä –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
st.write(f"–†–∞–∑–º–µ—Ä –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: {data.shape}")
st.dataframe(data.head(10))

# ==========================
# 5. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∏—á–∏ –∏ —Ç–∞—Ä–≥–µ—Ç
# ==========================
# –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ suicides_100k_pop ‚Äì —ç—Ç–æ —Ç–∞—Ä–≥–µ—Ç
target_col = 'suicides_100k_pop'
feature_cols = [c for c in data.columns if c not in ['suicides_100k_pop','suicides_no','country']]

X = data[feature_cols]
y = data[target_col]

# ==========================
# 6. –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/test
# ==========================
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=test_size,
    random_state=42
)

# ==========================
# 7. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
# ==========================
st.subheader("–û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π")

models = {
    "Linear Regression": LinearRegression(),
    "Decision Tree": DecisionTreeRegressor(max_depth=max_depth, random_state=42),
    "Random Forest": RandomForestRegressor(n_estimators=n_estimators, max_depth=None, random_state=42),
    "KNN Regressor": KNeighborsRegressor(n_neighbors=k_neighbors)
}

results = []

for model_name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = mse**0.5
    r2 = r2_score(y_test, y_pred)

    results.append({
        'Model': model_name,
        'MAE': mae,
        'RMSE': rmse,
        'R^2': r2
    })

# –í—ã–≤–æ–¥–∏–º —Ç–∞–±–ª–∏—á–∫—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
results_df = pd.DataFrame(results).sort_values(by='RMSE', ascending=True)
st.write(results_df)

# ==========================
# 8. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
# ==========================

st.subheader("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (–ø—Ä–∏–º–µ—Ä—ã)")

selected_model = st.selectbox(
    "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¥–µ—Ç–∞–ª—å–Ω–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏:",
    list(models.keys())
)

model_obj = models[selected_model]
y_pred_sel = model_obj.predict(X_test)

# –ì—Ä–∞—Ñ–∏–∫: scatter "y_test vs y_pred"
fig1, ax1 = plt.subplots(figsize=(6, 6))
ax1.scatter(y_test, y_pred_sel, alpha=0.6)
ax1.set_xlabel("–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π suicides_100k_pop")
ax1.set_ylabel("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π suicides_100k_pop")
ax1.set_title(f"{selected_model}: –†–µ–∞–ª—å–Ω—ã–µ vs –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ")
# –õ–∏–Ω–∏—è y=x –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏
min_val = min(y_test.min(), y_pred_sel.min())
max_val = max(y_test.max(), y_pred_sel.max())
ax1.plot([min_val, max_val], [min_val, max_val], 'r--')
st.pyplot(fig1)

st.write("**–ü—Ä–∏–º–µ—Ä—ã (–ø–µ—Ä–≤—ã–µ 10 —Ç–æ—á–µ–∫ –∏–∑ —Ç–µ—Å—Ç–∞):**")
comparison_df = pd.DataFrame({
    'Actual': y_test.values[:10],
    'Predicted': y_pred_sel[:10]
})
st.dataframe(comparison_df)

# ==========================
# 9. (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –ú–Ω–æ–≥–æ–º–µ—Ä–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
# ==========================
# –ï—Å–ª–∏ –∑–∞—Ö–æ—Ç–∏–º 2D scatter –ø–æ 2 –ø—Ä–∏–∑–Ω–∞–∫–∞–º, –∞ —Ü–≤–µ—Ç = suicides_100k_pop
st.subheader("2D Scatter –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º (—Ü–≤–µ—Ç = —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è)")

numeric_features = [c for c in feature_cols if pd.api.types.is_numeric_dtype(data[c])]
default_2d = numeric_features[:2] if len(numeric_features) >= 2 else None

two_feats = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ 2 —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞", numeric_features, default=default_2d)
if len(two_feats) == 2:
    fig2, ax2 = plt.subplots(figsize=(7, 5))
    scatter = ax2.scatter(
        data[two_feats[0]],
        data[two_feats[1]],
        c=data[target_col],
        cmap='viridis',
        alpha=0.5
    )
    ax2.set_xlabel(two_feats[0])
    ax2.set_ylabel(two_feats[1])
    ax2.set_title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ—á–µ–∫ (—Ü–≤–µ—Ç = suicides_100k_pop)")
    plt.colorbar(scatter, label="–£—Ä–æ–≤–µ–Ω—å —Å–∞–º–æ—É–±–∏–π—Å—Ç–≤ (–Ω–∞ 100k)")
    st.pyplot(fig2)
else:
    st.write("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–æ–≤–Ω–æ 2 –ø—Ä–∏–∑–Ω–∞–∫–∞, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å 2D scatter.")

# ==========================
# 10. –ó–∞–≤–µ—Ä—à–∞—é—â–∞—è —á–∞—Å—Ç—å
# ==========================
st.write("""
---
**–í—ã–≤–æ–¥**: –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –º—ã –≤–∏–¥–∏–º, –∫–∞–∫–∞—è –º–æ–¥–µ–ª—å –ª—É—á—à–µ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç 
—á–∏—Å–ª–æ–≤–æ–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å (suicides_100k_pop) –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ, 
—Å —É—á—ë—Ç–æ–º –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –¥–æ–ª–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è.
""")
